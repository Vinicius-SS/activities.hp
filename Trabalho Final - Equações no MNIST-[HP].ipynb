{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projete e treine uma rede neural para efetuar um cálculo (soma, subtração, ou multiplicação) usando duas imagens do MNIST. \n",
    "\n",
    "Exemplos: \n",
    "* (Imagem do dígito 3) + (Imagem do dígito 5) = 8\n",
    "* (Imagem do dígito 2) - (Imagem do dígito 1) = 1\n",
    "* (Imagem do dígito 9) x (Imagem do dígito 5) = 45\n",
    "* (Imagem do dígito 1) + (Imagem do dígito 2) = 3\n",
    "\n",
    "Dicas: \n",
    "* A rede receberá duas entradas: um tensor contento duas imagens, e outro tensor contendo um inteiro que representa a operação\n",
    "* A saída sempre será um número inteiro \n",
    "* Os índices das operações são os seguintes: 0 - Soma, 1 - Subtração, 2 - Multiplicação\n",
    "* Pense em uma forma de transformar os inteiros que representam as operações em vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O código das célula abaixo contém funções para efetuar a carga dos dados, treinamento e teste dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        device,\n",
    "        lr,\n",
    "        nb_epochs=3,\n",
    "        log_interval=100,\n",
    "    ):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    print('\\n* * * Evaluating * * *')\n",
    "    acc = test(model, device, criterion, test_loader)\n",
    "    \n",
    "    for epoch in range(1, nb_epochs + 1):\n",
    "        print('\\n* * * Training * * *')\n",
    "        train_epoch(\n",
    "            model=model, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            epoch=epoch, \n",
    "            log_interval=log_interval\n",
    "        )\n",
    "        print('\\n* * * Evaluating * * *')\n",
    "        acc = test(model, device, criterion, test_loader)\n",
    "    \n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root='../data', \n",
    "            train=True, \n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        ),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root='../data', \n",
    "            train=False, \n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        ),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "operators = OrderedDict({\n",
    "    '': -1,\n",
    "    '+': 0,\n",
    "    '-': 1,\n",
    "    '*': 2,\n",
    "})\n",
    "\n",
    "n_operators = len(operators)-1\n",
    "operators_i2o = {v: k for k, v in operators.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    digits, labels = zip(*data)\n",
    "    digits = torch.stack(digits, 0).float()\n",
    "    labels = torch.stack(labels, 0)\n",
    "    \n",
    "    digits_idxs_mask = sample_digits(digits, 2)\n",
    "    \n",
    "    new_data = digits[digits_idxs_mask]\n",
    "    digit_targets = labels[digits_idxs_mask]\n",
    "    \n",
    "    sampled_ops = sample_operators(len(new_data), 1, total_ops=3)\n",
    "    target, equation_str = make_ground_truth(digit_targets, sampled_ops)\n",
    "\n",
    "    return new_data, target, equation_str, sampled_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_digits(data, n_digits):\n",
    "    N = data.shape[0]\n",
    "    clear_diag = (1-torch.eye(N, N))\n",
    "    prob_matrix = clear_diag * torch.empty(N, N).uniform_(0, 1)\n",
    "    return torch.multinomial(prob_matrix, n_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_operators(n_samples, sample_n_ops, total_ops=3):\n",
    "    return torch.multinomial(torch.empty(n_samples, total_ops).uniform_(0, 1), sample_n_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_ground_truth(digit_targets, sampled_ops):\n",
    "    \n",
    "    result_targets = []\n",
    "    result_equations = []\n",
    "    \n",
    "    for ds, op in zip(digit_targets, sampled_ops):\n",
    "        op = torch.cat([op, -torch.ones(1).long()])\n",
    "        \n",
    "        equation = ''.join(['{}{}'.format(d, operators_i2o[o.item()]) for d, o in zip(ds, op)])\n",
    "        result_equations.append(equation)\n",
    "        result = eval(equation)\n",
    "        result_targets.append(result)\n",
    "    \n",
    "    return torch.LongTensor(result_targets)+9, result_equations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_instances(new_data, operators, pred_scores, nb_inst=5):\n",
    "    fig, axes = plt.subplots(nb_inst, 2, )\n",
    "    for i in range(nb_inst):\n",
    "        axs = axes[i]\n",
    "        data = new_data[i]\n",
    "        ops = operators[i]\n",
    "        pred = pred_scores[i]\n",
    "        for digit, ax in zip(data, axs):\n",
    "            digit = digit.cpu().permute(1, 2, 0).squeeze()        \n",
    "            ax.imshow(digit, cmap='gray')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        ax.text(-50, 15, operators_i2o[ops[0].item()], fontsize=24)\n",
    "        ax.text(30, 15, '={}'.format(pred.cpu().numpy()-9), fontsize=24)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "        model, \n",
    "        device, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        epoch, \n",
    "        log_interval\n",
    "    ):\n",
    "    model.train()\n",
    "    history = []\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data, target, eq_str, sampled_ops = data\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        sampled_ops= sampled_ops.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(digits=data, ops=sampled_ops)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(\n",
    "        model, \n",
    "        device, \n",
    "        criterion, \n",
    "        test_loader, \n",
    "        plot_images=True\n",
    "    ):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    mse_loss = nn.MSELoss()\n",
    "    total_mse = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target, eq_str, sampled_ops in test_loader:\n",
    "    \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            sampled_ops= sampled_ops.to(device)\n",
    "            \n",
    "            output = model(digits=data, ops=sampled_ops)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss                        \n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            \n",
    "            total_mse += mse_loss(pred.float().squeeze(), target.float()).item()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        plot_instances(new_data=data, operators=sampled_ops, pred_scores=pred)            \n",
    "            \n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test set:\\nAverage loss: {:.4f}\\nAccuracy: {}/{} ({:.2f}%)\\nErro Médio: {:.2f}\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy, total_mse))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parâmetros que você pode definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device_name = 'cpu'\n",
    "nb_epochs = 10\n",
    "log_interval = 50\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferência dos dados\n",
    "\n",
    "#### Entrada da rede: digits=(batch, num_digitos, canais, altura, largura), ops=(batch, operador) \n",
    "* num_digitos=2\n",
    "* canais=1\n",
    "* altura\n",
    "* largura=28\n",
    "\n",
    "### Operadores \n",
    "* -1) Nenhum\n",
    "* 0) Soma (`+`)\n",
    "* 1) Subtração (`-`)\n",
    "* 2) Multiplicação (`*`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loaders(batch_size=batch_size)\n",
    "digit_images, eq_target, eq_str, operator_ids = next(iter(train_loader))\n",
    "\n",
    "plot_instances(digit_images, operator_ids, eq_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dados de entrada na rede:')\n",
    "print('Imagens   : ', digit_images.shape)\n",
    "print('Operadores: ', operator_ids.shape)\n",
    "print('... Ex Ops: ', operator_ids[:5].numpy().tolist(), operators)\n",
    "print('Classes   : ', eq_target.shape)\n",
    "print('... Ex Cls: ', eq_target[:5].numpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seu trabalho começa aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Implemente uma rede capaz de compreender o conteúdo das imagens do MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DigitsConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitsConvNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = DigitsConvNet()\n",
    "\n",
    "print(net)\n",
    "pred = net(torch.zeros(5, 1, 28, 28))\n",
    "print(pred.shape)\n",
    "\n",
    "assert pred.shape[0] == 5 and len(pred.shape) == 2\n",
    "print('Passed! Go to the next step.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Implemente uma rede neural capaz de resolver uma operação matemática entre duas imagens do MNIST. \n",
    "* **DICA**: Utilize a DigitsConvNet como um módulo dentro da EquationNet para extrair vetores de características de todas as imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EquationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EquationNet, self).__init__()\n",
    "        self.digitsConvNet = DigitsConvNet()\n",
    "        \n",
    "    def forward(self, digits, ops):\n",
    "        '''\n",
    "        Arguments:\n",
    "            digits (FloatTensor): cada linha contém duas imagens do MNIST. \n",
    "                                  Shape esperado: (batch, 2, 1, 28, 28)\n",
    "            ops (LongTensor): cada linha contém uma operação representada em formato de números inteiros (batch, 1).\n",
    "                              Shape esperado: (batch, 1)  \n",
    "        Return: \n",
    "            result (FloatTensor): cada linha [i] contém o resultado da operação ops[i] \n",
    "                    aplicada entre as duas imagens digits[i]. \n",
    "                    Note que a resposta deve ser discreta, isto é, representada através de um neurônio. \n",
    "                    Shape esperado: (batch, 91)\n",
    "        '''\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = EquationNet().to(device)\n",
    "print(model)\n",
    "\n",
    "# Init dummy data\n",
    "dummy_digits = torch.zeros(5, 2, 1, 28, 28).to(device)\n",
    "dummy_operators = torch.zeros(5, 1).long().to(device)\n",
    "# Forward \n",
    "dummy_pred = model(digits=dummy_digits, ops=dummy_operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check network's input and output\n",
    "assert dummy_pred.shape == (5, 91), 'Expected: (5, 10), Found: {}'.format(dummy_pred.shape)\n",
    "print('Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Treine seu modelo por algumas épocas e reporte o resultado. \n",
    "* **Dica**: com uma rede leve, em 4 épocas, é possível alcançar acurácia de >=95%, e um erro médio <=1500. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
